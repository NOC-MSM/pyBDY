# pyBDY Documentation

**Welcome to the documentation for pyBDY (NEMO lateral boundary conditions)**

## Introduction

pyBDY is a python package to generate lateral boundary conditions for regional NEMO model configurations.
It has been developed to uses geographical and depth information from an a source data (e.g. a global ocean
simulation) and translate them to a destination NEMO region simulation. It makes use of a kdtree approximate
nearest neighbour algorithm in order to provide a generic method of weighted average interpolation for any
flavour of ocean model. The available options are accessed either through a NEMO style namelist or a
convient GUI.

---

## Contents

- [Dependencies :globe_with_meridians:](#dependencies-)
- [Quick Start Installation :rocket:](#quick-start-installation-)
- [How to use pyBDY :mechanical_arm:](#how-to-use-pybdy-)
- [Function List :scroll:](#function-list-)

## Dependencies :globe_with_meridians:

pyBDY is installed under a conda/mamba environment to aid wider distribution and to facilitate development.
The key dependecies are listed below:

- netCDF4
- scipy
- numpy
- matplotlib
- cartopy
- thredds_crawler
- seawater
- pyqt5
- pyjnius
- cftime

A recent JAVA installation is also required.

---

## Quick Start Installation :rocket:

To get started, check out and set up an instance of the pyBDY GitHub [repository](https://github.com/NOC-MSM/pyBDY):

```sh
export PYBDY_DIR=$PWD/pyBDY
git clone git@github.com:NOC-MSM/pyBDY.git
```

??? tip "Helpful Tip..."

    - **It is not advised to checkout the respository in your home directory.**

Creating a specific conda virtual environment is highly recommended ([click here for more about virtual
enviroments](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)).
Load conda (e.g. through anaconda/miniforge) and create the environment through the provided `environment.yml` file.

```sh
cd $PYBDY_DIR
conda env create -n pybdy -f environment.yml
```

Activate the new environment

```sh
conda activate pybdy
```

Install pyBDY

```sh
pip install -e .
```

Make sure the Java Runtime Environment is set:

```sh
export JAVA_HOME=path_to_jre
```

Generalised methods for defining paths are as follows:

```
export JAVA_HOME=$(readlink -f $(which java)) # UNIX
export JAVA_HOME=$(/usr/libexec/java_home)    # Mac
```

To check that pyBDY have been correctly installed in the virtual environment,
enter the following command:

```
pybdy -v
```

If it has you should see the help usage prompt:

```
usage: pybdy -g -s <namelist.bdy>
```

If not please see the troubleshooting pages for common causes as
to why the installation may fail.

To deactivate the conda environment:

```
conda deactivate
```

## How to use pyBDY :mechanical_arm:

In this documentation "bdy points" refer to the output boundary points generated by pyBDY.
Fist follow the installation instructions [Quick Start Installation](#quick-start-installation-).

### Step 1: File Preparation

Copy and paste the following files into your working directory:

- `inputs/namelist_local.bdy`

- `inputs/grid_name_map.json`

- `inputs/src_data_local.ncml`

- `namelist.bdy`: Specifies file paths and configuration options.

- `grid_name_map.json`: Defines variable names in horizontal and vertical grid files.

- `src_data.ncml`: Aggregates and remaps source data variables for PyBDY.

### Step 2: Edit the Namelist `namelist_local.bdy`

Descriptions of all required variables are in
[`src/pybdy/variable.info`](https://github.com/NOC-MSM/pyBDY/blob/master/src/pybdy/variable.info).
Here we will summarise the main variables that will need changing to get started.

#### Key Namelist Parameters

- `sn_src_hgr`
- `sn_src_zgr`
- `sn_dst_hgr`
- `sn_dst_zgr`
- `sn_src_msk`
- `sn_bathy`
- `sn_nme_map`
- `sn_src_dir`
- `sn_dst_dir`
- `cn_mask_file`
- `ln_zinterp`
- `nn_rimwidth`

##### File Paths

Directory paths in bdy file can be relative or absolute.
The application picks the relative path from the current working directory.

- **`sn_src_hgr`**: Source horizontal grid file. Should include:

    - Ideal: `glamt`, `gphit`, `glamu`, `e1t`, `e2t`, `e1u`, etc.
    - Minimum: `nav_lat`, `nav_lon` on a 2D grid.
    - Use `ncdump -h` or `ncview` to inspect variables.
    - Map extra variable names in `grid_name_map.json` to avoid recalculation.

- **`sn_src_zgr`**: Source vertical grid file. May be the same as `sn_src_hgr`.

    - Ideal: `gdept`, `e3t`, `mbathy` (aka `bottom_level`)
    - If `mbathy` is missing:
        - Use `gdept_0` (1D depth)
        - Use any 2D field (e.g., `nav_lon`) for `mbathy`
        - **Not recommended for destination**
    - Map variables like `gdepw`, `gdepu`, `e3w` in `grid_name_map.json`
    - **Note**: Time-varying depths are not used in PyBDY.

- **`sn_dst_hgr`, `sn_dst_zgr`**: Destination equivalents of the above.

- **`sn_src_msk`**: Source mask file with variables:

    - `tmask`, `umask`, `vmask`, `fmask`

- **`sn_bathy`**: Destination bathymetry file with variable:

    - `Bathymetry`

    - Used to calculate boundary mask if `ln_mask_file` is unset.

    - Can be computed from `e3w` and `bottom_level`:

        ```python
        gdepw = np.cumsum(e3w, axis=1)
        grid = np.indices(bottom_level.shape)
        bathy = gdepw[bottom_level, grid[0], grid[1]]
        ```

- **`sn_nme_map`**: Path to `grid_name_map.json`

    - **Note**: `ncml` is no longer used for grid input. Use `grid_name_map.json` instead. See [`inputs/grid_name_map_readme.txt`](https://github.com/NOC-MSM/pyBDY/blob/master/inputs/grid_name_map_readme.txt) for variable descriptions.

- **`sn_src_dir`**: Path to `src_data.ncml`

    - This is an xml file that points to source data (not grid) paths. It can also include THREDDS URLs (see `inputs/namelist_remote.bdy` for example).
    - See `inputs` folder for more examples.

    Example structure:

    ```xml
    <ns0:netcdf xmlns:ns0="http://www.unidata.ucar.edu/namespaces/netcdf/ncml-2.2" title="aggregation example">
      <ns0:aggregation type="union">
        <ns0:netcdf>
          <ns0:aggregation type="joinExisting" dimName="time_counter">
            <ns0:scan location="/path_to_src_data/Data/" regExp=".*grid_T.*" />
          </ns0:aggregation>
        </ns0:netcdf>
        <ns0:netcdf>
          <ns0:aggregation type="joinExisting" dimName="time_counter">
            <ns0:scan location="/path_to_src_data/Data/" regExp=".*grid_U.*" />
          </ns0:aggregation>
        </ns0:netcdf>
        <ns0:netcdf>
          <ns0:aggregation type="joinExisting" dimName="time_counter">
            <ns0:scan location="/path_to_src_data/Data/" regExp=".*grid_V.*" />
          </ns0:aggregation>
        </ns0:netcdf>
      </ns0:aggregation>
    </ns0:netcdf>
    ```

    - Regular expression (Regex) is a special text string that can be used in the xml file for describing a search pattern to match against some text. You may compare using regex to filter what files to include in your datasets against using wildcard (\*) to specify a file search pattern in your computer. More information on Regex patterns can be found here [Regex](https://learn.microsoft.com/en-us/dotnet/standard/base-types/regular-expression-language-quick-reference).

- **`sn_dst_dir`**: Output directory for PyBDY data

##### Other Settings

- **`cn_mask_file`** *(optional)*: Used to define open boundaries.

    - Values: `-1` (out-of-domain), `0` (land), `1` (water)
    - If not provided, PyBDY uses bathymetry to infer boundaries

- **`ln_zinterp`**: Disables vertical interpolation if `false` and source uses zco levels.

    - Output will match source vertical levels
    - If source uses zps or sco, this will be set to `true` automatically

- **`nn_rimwidth`**: Number of interior boundary points to generate

    - Typical value: `9`
    - For tidal boundaries: `1`

#### Time Settings

- Ensure `time_counter` exists in source files
- Files must be time-ascending
- NetCDF time metadata must include:
    - `calendar`: `"gregorian"`, `"noleap"`, or `"360_day"`
    - `units`: `"seconds since YYYY-MM-DD hh:mm:ss"`

##### Required Namelist Time Parameters

- **`sn_date_start`**: Start date for output (format: `YYYY-MM-DD`)
- **`sn_date_end`**: End date for output (format: `YYYY-MM-DD`)
    - The start date and end date of output must fall within the source data time range.
- **`sn_dst_calendar`**: Output calendar format
- **`sn_date_origin`**: Time counter reference date for output (format: `YYYY-MM-DD`)
- **`ln_time_interpolation`**: If `true`, interpolate to daily steps.
    - If `false`, output uses source data calendar (monthly steps only)

### Step 3: Running pyBDY

To use pyBDY, the following command is entered: (the example will run a benchmarking test):

```
pybdy -s /path/to/namelist/file (e.g. ./inputs/namelist_remote.bdy)
```

This command line tool reads a BDY file, extracts boundary data and prepares the data for a NEMO simulation.

## Function List :scroll:

## Tidal Boundary Conditions Generation

By providing a global tidal model dataset (TPXO and FES are currently supported) pyBDY can generate boundary conditions for the NEMO configuration supplied using the namelist file.

### Namelist options

To use the namelist needs to be configured with the required options. These are listed below:

```
ln_tide        = .true.              !  =T : produce bdy tidal conditions
sn_tide_model  = 'FES2014'           !  Name of tidal model. Accepts FES2014, TPXO7p2, or TPXO9v5
clname(1)      = 'M2'                !  constituent name
clname(2)      = 'S2'
clname(3)      = 'K2'
clname(4)      = 'O1'
clname(5)      = 'P1'
clname(6)      = 'Q1'
clname(7)      = 'M4'
ln_trans       = .true.              !  interpolate transport rather than velocities
! location of TPXO7.2 data
sn_tide_grid_7p2   = './inputs/tpxo7.2/grid_tpxo7.2.nc'
sn_tide_h          = './inputs/tpxo7.2/h_tpxo7.2.nc'
sn_tide_u          = './inputs/tpxo7.2/u_tpxo7.2.nc'
! location of TPXO9v5 data: single constituents per file
sn_tide_grid_9p5   = './inputs/TPXO9_atlas_v5_nc/grid_tpxo9_atlas_30_v5.nc'
sn_tide_dir        = './inputs/TPXO9_atlas_v5_nc/'
! location of FES2014 data
sn_tide_fes        = './inputs/FES2014/'
```

These options define the location of the tidal model datasets, note this differs depending on model as TPXO has all harmonic constants in one netcdf file whereas FES has three separate netcdf files (one for amplitude two for currents) for each constant. Extra harmonics can be appended to the clname(n) list. FES supports 34 constants and TPXO7.2 has 13 to choose from. Other versions of TPXO should work with pyBDY but have not been yet been tested. NOTE FES dataset filenames must have be in the format of constituent then type. e.g.:

```
M2_Z.nc (for amplitude)
M2_U.nc (for U component of velocity)
M2_V.nc (for V component of velocity)
```

If this is not undertaken the pyBDY will not recognise the files. TPXO data files are specified directly so these can be anyname although it is best to stick with the default names as shown above. So far the tidal model datasets have been downloaded and used locally but could also be stored on a THREDDS server although this has not been tested with the global tide models.

Other options include “ln_tide” a boolean that when set to true will generate tidal boundaries. “sn_tide_model” is a string that defines the model to use, currently only “fes” or “tpxo” are supported. “ln_trans” is a boolean that when set to true will interpolate transport rather than velocities.

### Harmonic Output Checker

There is an harmonic output checker that can be utilised to check the output of pyBDY with a reference tide model. So far the only supported reference model is FES but TPXO will be added in the future. Any tidal output from pyBDY can be checked (e.g. FES and TPXO). While using the same model used as input to check output doesn’t improve accuracy, it does confirm that the output is within acceptable/expected limits of the nearest model reference point.

There are differences as pyBDY interpolates the harmonics and the tidal checker does not, so there can be some difference in the values particularly close to coastlines.

The checker can be enabled by editing the following in the relevent bdy file:

```
ln_tide_checker = .true.                ! run tide checker on pyBDY tide output
sn_ref_model    = 'fes'                 ! which model to check output against (FES only)
```

The boolean determines if to run the checker or not, this takes place after creating the interpolated harmonics and writing them to disk. The string denotes which tide model to use as reference, so far only FES is supported. The string denoting model is not strictly needed, by default fes is used.

The checker will output information regarding the checking to the NRCT log, and also write an spreadsheet to the output folder containing any exceedance values, the closest reference model value and their locations. Amplitude and phase are checked independently, so both have latitude and longitude associated with them. It is also useful to know the amplitude of a exceeded phase to see how much impact it will have so this is also written to the spreadsheet. An example output is shown below, as can be seen the majority of the amplitudes, both the two amplitudes exceedances and the ones associated with the phase exceedances are low (~0.01), so can most likely be ignored. There a few phase exceedances that have higher amplitudes (~0.2) which would potentially require further investigation. A common reason for such an exceedance is due to coastlines and the relevant point being further away from an FES data point.

The actual thresholds for both amplitude and phase are based on the amplitude of the output or reference, this is due to different tolerances based on the amplitude. e.g. high amplitudes should have lower percentage differences to the FES reference, than lower ones simply due to the absolute amount of the ampltiude itself, e.g. a 0.1 m difference for a 1.0 m amplitude is acceptable but not for a 0.01 m amplitude. The smaller amplitudes contribute less to the overall tide height so larger percentage differences are acceptable. The same also applies to phases, where large amplitude phases have little room for differences but at lower amplitudes this is less critical so a higher threshold is tolerated.

The following power functions are used to determine what threshold to apply based on the reference model amplitude.

#### Amplitude Threshold

```
Percentage Exceedance = 26.933 * Reference Amplitude ^ -0.396’
```

#### Phases Threshold

```
Phase Exceedance = 5.052 * pyBDY Amplitude ^ -0.60
```

## CMEMS Downloader

## Troubleshooting

Always check the pyBDY log file. This is usually saved in the working directory of pyBDY as nrct.log. It gives helpful information which may help to diagnose issues. E.g. ValueErrors that are result of a THREDDS server being down and unable to provide data files.
